{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O0iOeMBRIvBd"
      },
      "source": [
        "# Conditional Generative Adversarial Network\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r35tkP1HJBw6"
      },
      "source": [
        "### Loading datset and preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68QtTPrkHpGD"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\r\n",
        "\r\n",
        "# load mnist x_train\r\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTIwCDfOJerF",
        "outputId": "5793808b-54af-417d-88cf-b1c4f6cbee55"
      },
      "source": [
        "import numpy as np\r\n",
        "from collections import Counter\r\n",
        "from tensorflow.keras.utils import to_categorical\r\n",
        "\r\n",
        "\"\"\" Preprocessing \"\"\"\r\n",
        "\r\n",
        "# create batch_dim\r\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\r\n",
        "\r\n",
        "# convert to keras compatible float\r\n",
        "x_train = x_train.astype(np.float32)\r\n",
        "\r\n",
        "# count different classes\r\n",
        "num_classes = len(Counter(y_train).keys())\r\n",
        "\r\n",
        "# create to_categorical labels\r\n",
        "y_train = to_categorical(y_train, num_classes)\r\n",
        "y_test = to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "# normalization to inputs between [-1, 1]\r\n",
        "MAX = np.max(x_train)\r\n",
        "x_train = (x_train / (MAX/2)) - 1\r\n",
        "\r\n",
        "print(f\"Data_shape: {x_train.shape} - Input_range: [{np.min(x_train)}, {np.max(x_train)}]\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data_shape: (60000, 28, 28, 1) - Input_range: [-1.0, 1.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8_96kFbLeDz"
      },
      "source": [
        "### Discriminator Network\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0JBRysYLZ6-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "029ecc4c-f906-49b9-a276-be3214319a79"
      },
      "source": [
        "from tensorflow.keras.layers import Activation\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.layers import Flatten\r\n",
        "from tensorflow.keras.layers import Input\r\n",
        "from tensorflow.keras.layers import Concatenate\r\n",
        "from tensorflow.keras.layers import LeakyReLU\r\n",
        "from tensorflow.keras.layers import Dropout\r\n",
        "from tensorflow.keras.models import Model\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "\r\n",
        "img_shape = x_train.shape[1:]\r\n",
        "\r\n",
        "img = Input(shape=(img_shape))\r\n",
        "label = Input(shape=(num_classes,))\r\n",
        "img_flatten = Flatten()(img)\r\n",
        "\r\n",
        "x = Concatenate()([img_flatten, label])\r\n",
        "x = Dense(units=512)(x)\r\n",
        "x = LeakyReLU(alpha=0.2)(x)\r\n",
        "x = Dropout(rate=0.25)(x)\r\n",
        "x = Dense(units=512)(x)\r\n",
        "x = LeakyReLU(alpha=0.2)(x)\r\n",
        "x = Dropout(rate=0.25)(x)\r\n",
        "x = Dense(units=1)(x)\r\n",
        "d_pred = Activation(\"sigmoid\")(x)\r\n",
        "\r\n",
        "DISCRIMINATOR = Model(inputs=[img, label], outputs=d_pred)\r\n",
        "DISCRIMINATOR.summary()\r\n",
        "\r\n",
        "DISCRIMINATOR.compile(\r\n",
        "    loss=\"binary_crossentropy\",\r\n",
        "    optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\r\n",
        "    metrics=[\"accuracy\"]\r\n",
        ")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 28, 28, 1)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 784)          0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 794)          0           flatten[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          407040      concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 512)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 512)          0           leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 512)          262656      dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, 512)          0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 512)          0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1)            513         dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 1)            0           dense_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 670,209\n",
            "Trainable params: 670,209\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BZPJ67uPD8C"
      },
      "source": [
        "### Generator Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eP1eEG1PF-u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a06d54-5f3f-46d2-91ce-c342a91560cb"
      },
      "source": [
        "from tensorflow.keras.layers import BatchNormalization\r\n",
        "from tensorflow.keras.layers import Reshape\r\n",
        "\r\n",
        "z_dim = 100\r\n",
        "\r\n",
        "noise = Input(shape=(z_dim,))\r\n",
        "label = Input(shape=(num_classes,))\r\n",
        "\r\n",
        "x = Concatenate()([noise, label])\r\n",
        "x = Dense(units=512)(x)\r\n",
        "x = LeakyReLU(alpha=0.2)(x)\r\n",
        "x = BatchNormalization()(x)\r\n",
        "x = Dense(units=1024)(x)\r\n",
        "x = LeakyReLU(alpha=0.2)(x)\r\n",
        "x = BatchNormalization()(x)\r\n",
        "x = Dense(np.prod(img_shape))(x)\r\n",
        "x = Activation(\"tanh\")(x)\r\n",
        "img = Reshape(img_shape)(x)\r\n",
        "\r\n",
        "GENERATOR = Model(inputs=[noise, label], outputs=img)\r\n",
        "GENERATOR.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 100)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_4 (InputLayer)            [(None, 10)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 110)          0           input_3[0][0]                    \n",
            "                                                                 input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 512)          56832       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, 512)          0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 512)          2048        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1024)         525312      batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, 1024)         0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 1024)         4096        leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 784)          803600      batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 784)          0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "reshape (Reshape)               (None, 28, 28, 1)    0           activation_1[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 1,391,888\n",
            "Trainable params: 1,388,816\n",
            "Non-trainable params: 3,072\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1baHJqC7RjW0"
      },
      "source": [
        "### GAN Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x4YOCfcRir1"
      },
      "source": [
        "# combining DISCRIMINATOR and GENERATOR to GAN\r\n",
        "noise_in = Input(shape=(z_dim,)) # noise in\r\n",
        "label = Input(shape=(num_classes,)) # label in\r\n",
        "img = GENERATOR([noise_in, label]) # generated image\r\n",
        "DISCRIMINATOR.trainable = False\r\n",
        "d_pred = DISCRIMINATOR([img, label]) # prediction if image input is real or fake\r\n",
        "CGAN = Model(inputs=[noise_in, label], outputs=d_pred)\r\n",
        "\r\n",
        "CGAN.compile(\r\n",
        "    loss=\"binary_crossentropy\",\r\n",
        "    optimizer=Adam(learning_rate=0.0002, beta_1=0.5)\r\n",
        ")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ID_tCEFUyJ-"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSxyq2ACUWKE",
        "outputId": "d982f54a-047d-4c8f-ccc3-6433de0ef4f4"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "import os\r\n",
        "\r\n",
        "PATH = \"generated_images\"\r\n",
        "try:\r\n",
        "    os.makedirs(PATH)\r\n",
        "except FileExistsError:\r\n",
        "    pass\r\n",
        "\r\n",
        "# creating labels for dataset\r\n",
        "batch_size = 128\r\n",
        "y_real = np.ones(shape=(batch_size, 1)) # 1 = 100% real\r\n",
        "y_fake = np.zeros(shape=(batch_size, 1)) # 0 = 0% real\r\n",
        "\r\n",
        "epochs=10_000\r\n",
        "\r\n",
        "for epoch in range(1, epochs+1):\r\n",
        "    # get random images from real dataset\r\n",
        "    rand_idxs = np.random.randint(low=0, high=x_train.shape[0], size=batch_size)\r\n",
        "    real_imgs = x_train[rand_idxs]\r\n",
        "    classes = y_train[rand_idxs] # get label to image\r\n",
        "    # generate fake images for training\r\n",
        "    noise = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim)) # noise vector (32, 100)\r\n",
        "    fake_imgs = GENERATOR([noise, classes], training=False)\r\n",
        "    # train DISCRIMINATOR\r\n",
        "    d_loss_real = DISCRIMINATOR.train_on_batch([real_imgs, classes], y_real)\r\n",
        "    d_loss_fake = DISCRIMINATOR.train_on_batch([fake_imgs, classes], y_fake)\r\n",
        "    d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\r\n",
        "    # train GENERATOR\r\n",
        "    noise = np.random.normal(loc=0.0, scale=1.0, size=(batch_size, z_dim))\r\n",
        "    g_loss = CGAN.train_on_batch([noise, classes], y_real)\r\n",
        "\r\n",
        "    # saving every 1000 steps\r\n",
        "    if((epoch % 1000) == 0) or (epoch==1):\r\n",
        "        print(\r\n",
        "            f\"{epoch} - D_loss: {round(d_loss[0], 4)}\"\r\n",
        "            f\" D_acc: {round(d_loss[1], 4)}\"\r\n",
        "            f\" G_loss: {round(g_loss, 4)}\"\r\n",
        "        )\r\n",
        "\r\n",
        "        rows, cols = 2, 5\r\n",
        "        noise = np.random.normal(loc=0.0, scale=1.0, size=(rows * cols, z_dim))\r\n",
        "        labels = np.random.randint(0, num_classes, 10)\r\n",
        "        labels_categorical = to_categorical(labels, num_classes=num_classes)\r\n",
        "        gen_imgs = GENERATOR.predict([noise, labels_categorical]) # generating image\r\n",
        "        gen_imgs = 0.5 * gen_imgs + 0.5\r\n",
        "        fig, axs = plt.subplots(rows, cols)\r\n",
        "        cnt = 0\r\n",
        "        for i in range(rows):\r\n",
        "            for j in range(cols):\r\n",
        "                axs[i, j].imshow(gen_imgs[cnt, :, :, 0], cmap=\"gray\")\r\n",
        "                axs[i, j].set_title(f\"Digit: {labels[cnt]}\")\r\n",
        "                axs[i, j].axis(\"off\")\r\n",
        "                cnt +=1\r\n",
        "        img_name = f\"{epoch}.png\"\r\n",
        "        fig.savefig(os.path.join(PATH, img_name))\r\n",
        "        plt.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 - D_loss: 0.8023 D_acc: 0.4922 G_loss: 0.8261\n",
            "1000 - D_loss: 0.5604 D_acc: 0.7266 G_loss: 0.9761\n",
            "2000 - D_loss: 0.5225 D_acc: 0.7578 G_loss: 1.2688\n",
            "3000 - D_loss: 0.6139 D_acc: 0.6719 G_loss: 1.082\n",
            "4000 - D_loss: 0.6424 D_acc: 0.6211 G_loss: 0.9661\n",
            "5000 - D_loss: 0.6575 D_acc: 0.5977 G_loss: 0.9516\n",
            "6000 - D_loss: 0.6726 D_acc: 0.5664 G_loss: 0.916\n",
            "7000 - D_loss: 0.6795 D_acc: 0.6133 G_loss: 0.8233\n",
            "8000 - D_loss: 0.6898 D_acc: 0.5273 G_loss: 0.8383\n",
            "9000 - D_loss: 0.6791 D_acc: 0.6094 G_loss: 0.8347\n",
            "10000 - D_loss: 0.6918 D_acc: 0.5273 G_loss: 0.8173\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}